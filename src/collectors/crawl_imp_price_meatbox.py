from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import pandas as pd
import time
import os
import re
import shutil
from datetime import datetime
from io import StringIO

# [íŒŒì¼ ì •ì˜ì„œ]
# - íŒŒì¼ëª…: crawl_imp_price_meatbox.py
# - ì—­í• : ìˆ˜ì§‘ ë° ë°ì´í„° ê²½ëŸ‰í™” (ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±°)
# - ëŒ€ìƒ: ìˆ˜ì…ìœ¡ (ë¯¸íŠ¸ë°•ìŠ¤)
# - ë°©ì‹: ì¼ë°˜ ë¸Œë¼ìš°ì € ëª¨ë“œ (Headless X)

URL = "https://www.meatbox.co.kr/fo/sise/siseListPage.do"

def get_price_data():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # ë“œë¼ì´ë²„ ê²½ë¡œ (src í´ë”ì— chromedriver.exeê°€ ìˆìŒ)
    src_dir = os.path.dirname(current_dir)
    driver_path = os.path.join(src_dir, "chromedriver.exe")
    
    # ê²½ë¡œ ì„¤ì • (í”„ë¡œì íŠ¸ ë£¨íŠ¸: srcì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬)
    project_root = os.path.dirname(src_dir)
    processed_dir = os.path.join(project_root, "data", "1_processed")
    
    master_file = os.path.join(processed_dir, "master_price_data.csv")
    backup_file = os.path.join(processed_dir, "master_price_data_backup_full.csv")
    
    today_date = datetime.now().strftime("%Y-%m-%d")

    # [í•µì‹¬] ìš°ë¦¬ê°€ ë‚¨ê¸¸ ìµœì¢… ì»¬ëŸ¼ ì •ì˜
    target_cols = ['date', 'part_name', 'country', 'wholesale_price', 'brand']

    print("="*60)
    print(f"[ì‹œìŠ¤í…œ] ë¯¸íŠ¸ë°•ìŠ¤ ì‹œì„¸ ìˆ˜ì§‘ (ì¼ë°˜ ë¸Œë¼ìš°ì € ëª¨ë“œ)")
    print(f"[ì„¤ì •] ì €ì¥ ì»¬ëŸ¼: {target_cols}")
    print("="*60)

    # 1. [ì‚¬ì „ ìµœì í™”] ê¸°ì¡´ íŒŒì¼ ë¡œë“œ ë° ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±°
    if os.path.exists(master_file):
        try:
            # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ì „ì²´ ë°±ì—… í•œ ë²ˆ ìƒì„±
            shutil.copy(master_file, backup_file)
            
            # ë¡œë“œ
            df_master = pd.read_csv(master_file)
            
            # ê¸°ì¡´ ì»¬ëŸ¼ ì •ë¦¬
            for col in target_cols:
                if col not in df_master.columns:
                    df_master[col] = '-' if col == 'brand' else ""
            
            df_master = df_master[target_cols] 

            # ì˜¤ëŠ˜ ë‚ ì§œ ì¤‘ë³µ ë° ë¹ˆ ë°ì´í„° ì œê±°
            cond_empty = df_master['part_name'].isna() | (df_master['part_name'] == '')
            cond_today = df_master['date'] == today_date
            
            df_master = df_master[~(cond_empty | cond_today)]
            
            print(f"[íŒŒì¼ ì •ë¦¬] ê¸°ì¡´ íŒŒì¼ ìµœì í™” ì™„ë£Œ (ì”ì—¬ {len(df_master)}í–‰)")
                
        except Exception as e:
            print(f"[ê²½ê³ ] íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (ì§„í–‰í•¨): {e}")
            df_master = pd.DataFrame(columns=target_cols) 
    else:
        df_master = pd.DataFrame(columns=target_cols)

    # ------------------------------------------------------------------
    # 2. [í¬ë¡¤ë§] ë°ì´í„° ìˆ˜ì§‘ (Headless í•´ì œ)
    # ------------------------------------------------------------------
    chrome_options = Options()
    
    # â˜… Headless ëª¨ë“œ ì£¼ì„ ì²˜ë¦¬ (ì°½ì´ ëœ¨ë„ë¡ ì„¤ì •)
    # chrome_options.add_argument("--headless") 
    
    # [ì¤‘ìš”] ë´‡ íƒì§€ íšŒí”¼ë¥¼ ìœ„í•œ User-Agent ì„¤ì • (ì‚¬ëŒì¸ ì²™í•˜ê¸°)
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--start-maximized") # ì‹œì‘í•  ë•Œ ì°½ ìµœëŒ€í™”

    # ë¶ˆí•„ìš”í•œ ë¡œê·¸ ìˆ¨ê¸°ê¸°
    chrome_options.add_argument("--log-level=3")
    
    if os.path.exists(driver_path):
        service = Service(executable_path=driver_path)
        driver = webdriver.Chrome(service=service, options=chrome_options)
    else:
        driver = webdriver.Chrome(options=chrome_options)

    # ì°½ ìµœëŒ€í™” (í™•ì‹¤í•˜ê²Œ)
    driver.maximize_window()
    driver.implicitly_wait(10)
    
    print(f"\n[ìˆ˜ì§‘] ì‚¬ì´íŠ¸ ì ‘ì† ì¤‘... (ë¸Œë¼ìš°ì €ë¥¼ í™•ì¸í•˜ì„¸ìš”)")
    driver.get(URL)
    
    raw_dfs = []
    current_page = 1 
    
    try:
        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° (í…Œì´ë¸”ì´ ëœ° ë•Œê¹Œì§€)
        wait = WebDriverWait(driver, 20)
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "tbody tr")))

        while True:
            print(f"[ìˆ˜ì§‘] {current_page}í˜ì´ì§€... ", end="")
            
            # í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
            html = driver.page_source
            
            try:
                # í…Œì´ë¸” íŒŒì‹±
                dfs = pd.read_html(StringIO(html))
                candidates = []
                for df in dfs:
                    cols_str = " ".join([str(c) for c in df.columns])
                    if "í’ˆëª©" in cols_str or "ë³´ê´€" in cols_str:
                        if len(df) > 1: candidates.append(df)
                
                if candidates:
                    target_df = max(candidates, key=len)
                    raw_dfs.append(target_df)
                    print(f"OK ({len(target_df)}ê±´)")
                else:
                    print("Skip (í…Œì´ë¸” ì—†ìŒ)")

            except Exception as e:
                print(f"Err (íŒŒì‹± ì‹¤íŒ¨)")

            # ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ë¡œì§
            time.sleep(1.5) # ì‚¬ëŒì´ ëˆ„ë¥´ëŠ” ê²ƒì²˜ëŸ¼ ì•½ê°„ ëŒ€ê¸°

            next_page = current_page + 1
            moved = False
            
            # í˜ì´ì§€ ë²„íŠ¼ í´ë¦­ ì‹œë„ (3íšŒ ì¬ì‹œë„)
            for attempt in range(3):
                try:
                    target_btn = None
                    try:
                        # ìˆ«ì ë²„íŠ¼ ì°¾ê¸°
                        target_btn = driver.find_element(By.XPATH, f"//a[normalize-space()='{next_page}']")
                    except NoSuchElementException:
                        # ìˆ«ì ë²„íŠ¼ ì—†ìœ¼ë©´ 'ë‹¤ìŒ(Next)' í™”ì‚´í‘œ ì°¾ê¸°
                        target_btn = driver.find_element(By.XPATH, "//a[contains(@class, 'next')]")
                    
                    if target_btn:
                        driver.execute_script("arguments[0].click();", target_btn)
                        moved = True
                        break # ì„±ê³µí•˜ë©´ ì¬ì‹œë„ ì¢…ë£Œ
                except:
                    time.sleep(1)
            
            if moved:
                current_page += 1
                time.sleep(1) # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            else:
                print("\n[ìˆ˜ì§‘] ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ê±°ë‚˜ ë§ˆì§€ë§‰ì…ë‹ˆë‹¤.")
                break
            
    except Exception as e:
        print(f"\n[ì—ëŸ¬] í¬ë¡¤ë§ ì¤‘ë‹¨: {e}")
    finally:
        driver.quit()
        print("[ì¢…ë£Œ] ë¸Œë¼ìš°ì €ë¥¼ ë‹«ì•˜ìŠµë‹ˆë‹¤.")
        
    # 3. [ë°ì´í„° ë³‘í•©] í•„ìš”í•œ 5ê°œ ì»¬ëŸ¼ë§Œ ìƒì„±
    if raw_dfs:
        full_df = pd.concat(raw_dfs, ignore_index=True)
        
        try:
            # ì „ì²˜ë¦¬
            clean_df = full_df.iloc[:, [1, 3, 4]].copy()
            clean_df.columns = ['í’ˆëª©ëª…', 'ë³´ê´€', 'ë„ë§¤ì‹œì„¸_raw']
            
            # "ê´€ì‹¬ìƒí’ˆ ë“±ë¡í•˜ê¸°" í…ìŠ¤íŠ¸ ì œê±°
            clean_df['í’ˆëª©ëª…'] = clean_df['í’ˆëª©ëª…'].astype(str).str.replace('ê´€ì‹¬ìƒí’ˆ ë“±ë¡í•˜ê¸°', '', regex=False).str.strip()
            
            clean_df = clean_df[clean_df['ë³´ê´€'].astype(str).str.contains("ëƒ‰ë™")]
            clean_df['ì›ì‚°ì§€'] = clean_df['í’ˆëª©ëª…'].apply(lambda x: 'ë¯¸êµ­' if 'ë¯¸êµ­' in str(x) else ('í˜¸ì£¼' if 'í˜¸ì£¼' in str(x) else 'ê¸°íƒ€'))
            clean_df = clean_df[clean_df['ì›ì‚°ì§€'] != 'ê¸°íƒ€']
            
            def extract_price(text):
                text = str(text)
                digits = re.sub(r'[^0-9]', '', text.split('ì›')[0])
                return int(digits) if digits else 0
            
            clean_df['ë„ë§¤ì‹œì„¸'] = clean_df['ë„ë§¤ì‹œì„¸_raw'].apply(extract_price)
            clean_df = clean_df[clean_df['ë„ë§¤ì‹œì„¸'] > 0]
            
            clean_df = clean_df.reset_index(drop=True)

            # ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
            data_dict = {
                'date': [today_date] * len(clean_df),
                'part_name': clean_df['í’ˆëª©ëª…'].tolist(),
                'country': clean_df['ì›ì‚°ì§€'].tolist(),
                'wholesale_price': clean_df['ë„ë§¤ì‹œì„¸'].tolist(),
                'brand': ['-'] * len(clean_df)
            }
            
            final_df = pd.DataFrame(data_dict)
            
            new_master_df = pd.concat([df_master, final_df], ignore_index=True)
            new_master_df = new_master_df.sort_values(by=['date', 'country', 'part_name'])
            
            new_master_df.to_csv(master_file, index=False, encoding='utf-8-sig')
            
            print("\n" + "="*60)
            print(f"âœ… ìˆ˜ì§‘ ë° ì €ì¥ ì™„ë£Œ!")
            print(f"ğŸ“Š ìµœì¢… ë°ì´í„°: {len(new_master_df)}í–‰ (ì˜¤ëŠ˜ ìˆ˜ì§‘: {len(final_df)}ê±´)")
            print("="*60)

        except Exception as e:
            print(f"[ì˜¤ë¥˜] ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("\n[ê²½ê³ ] ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    get_price_data()