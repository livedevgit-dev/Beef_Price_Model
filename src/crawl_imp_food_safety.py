import time
import os
import re
import pandas as pd
import urllib3
import sys
import warnings
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta

# ì…€ë ˆë‹ˆì›€ ê´€ë ¨ ëª¨ë“ˆ
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, ElementClickInterceptedException

# [íŒŒì¼ ì •ì˜ì„œ]
# - íŒŒì¼ëª…: crawl_imp_food_safety.py
# - ì—­í• : ìˆ˜ì§‘ (ì‹ì•½ì²˜ ìˆ˜ì…ì¶•ì‚°ë¬¼ ê²€ì—­ì‹¤ì )
# - ëŒ€ìƒ: ìˆ˜ì… ì†Œê³ ê¸° (ë¯¸êµ­/í˜¸ì£¼, ëƒ‰ë™ ê¸°ì¤€)
# - ì£¼ìš” ìˆ˜ì •: ë¶€ìœ„ë³„ í•©ê³„ ì»¬ëŸ¼ëª…('ë¶€ìœ„ë³„_ê³„_í•©ê³„') í†µì¼ ë° ìë™ í•©ì‚° ë¡œì§ ê°•í™”

# ê²½ê³  ë¬´ì‹œ ì„¤ì •
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
warnings.filterwarnings('ignore', category=UserWarning, module='pandas')
pd.options.mode.chained_assignment = None 

# =========================================================
# 1. ì„¤ì • ë° ê²½ë¡œ
# =========================================================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
SAVE_DIR = os.path.join(PROJECT_ROOT, "data", "0_raw")
os.makedirs(SAVE_DIR, exist_ok=True)

MASTER_FILE = os.path.join(SAVE_DIR, "master_import_volume.csv")

# =========================================================
# 2. ë‚ ì§œ ê³„ì‚°
# =========================================================
def get_next_month_from_master():
    if not os.path.exists(MASTER_FILE): 
        print(" â„¹ï¸ ê¸°ì¡´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. 2019-01-01ë¶€í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        return "2019-01-01"
    
    try:
        df = pd.read_csv(MASTER_FILE)
        if 'std_date' not in df.columns:
            return "2019-01-01"
            
        df['dt_parsed'] = pd.to_datetime(df['std_date'], errors='coerce')
        if df['dt_parsed'].isnull().sum() > len(df) / 2:
            try:
                df['dt_parsed'] = pd.to_datetime(df['std_date'], format='%b-%y', errors='coerce')
            except: pass
        
        if df['dt_parsed'].isnull().all():
             return "2019-01-01"

        last_date_obj = df['dt_parsed'].max()
        print(f" ğŸ“… ê¸°ì¡´ ë°ì´í„° ë§ˆì§€ë§‰ ì‹œì : {last_date_obj.strftime('%Y-%m')}")
        
        next_month = last_date_obj + relativedelta(months=1)
        return next_month.strftime("%Y-%m-%d")

    except Exception as e: 
        print(f" âš ï¸ ë‚ ì§œ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return "2019-01-01"

# =========================================================
# 3. ë“œë¼ì´ë²„ ì„¤ì •
# =========================================================
def setup_driver():
    chrome_options = Options()
    chrome_options.add_argument("--start-maximized")
    chrome_options.add_argument("--log-level=3")
    driver_path = os.path.join(CURRENT_DIR, "chromedriver.exe")
    service = Service(executable_path=driver_path)
    return webdriver.Chrome(service=service, options=chrome_options)

def js_click(driver, element):
    driver.execute_script("arguments[0].click();", element)

def close_any_popup(driver):
    try:
        for btn in driver.find_elements(By.XPATH, "//button[contains(text(), 'ë‹«ê¸°')]"):
            if btn.is_displayed(): js_click(driver, btn)
    except: pass

def wait_for_loading_bar(driver, timeout=10):
    try:
        WebDriverWait(driver, timeout).until(
            EC.invisibility_of_element_located((By.ID, "___processbar2"))
        )
    except: pass

# =========================================================
# 4. ë©”ë‰´ ì´ë™ ë° ì˜µì…˜ ì„¤ì •
# =========================================================
def move_to_target_menu_robust(driver):
    print("\n ğŸ‘‰ [ë©”ë‰´ ì´ë™] ìˆ˜ì…ì‹í’ˆ > ì¼ë°˜í˜„í™© > ê²€ì‚¬ì‹¤ì ")
    wait = WebDriverWait(driver, 30)
    driver.find_element(By.ID, "mf_trv_LeftMenu_label_1").click()
    time.sleep(1)
    driver.find_element(By.ID, "mf_trv_LeftMenu_label_2").click()
    time.sleep(1)
    driver.find_element(By.ID, "mf_trv_LeftMenu_label_17").click()
    time.sleep(3)

def set_search_options(driver):
    wait_for_loading_bar(driver)
    print(" ğŸ‘‰ [ì˜µì…˜ ì„¤ì •] ëƒ‰ë™ / ë¯¸êµ­, í˜¸ì£¼")
    
    driver.find_element(By.ID, "mf_win_main_subWindow0_wframe_sbx_prodSssnm_button").click()
    time.sleep(0.5)
    driver.find_element(By.ID, "mf_win_main_subWindow0_wframe_sbx_prodSssnm_itemTable_2").click() # ëƒ‰ë™
    time.sleep(0.5)

    driver.find_element(By.ID, "mf_win_main_subWindow0_wframe_ccb_SearchNtncd_button").click()
    time.sleep(1)
    try:
        driver.find_element(By.XPATH, "//*[contains(@id, 'itemTable_73')]").click() # ë¯¸êµ­
        time.sleep(0.2)
        driver.find_element(By.XPATH, "//*[contains(@id, 'itemTable_243')]").click() # í˜¸ì£¼
    except: pass
    driver.find_element(By.ID, "mf_win_main_subWindow0_wframe_ccb_SearchNtncd_button").click()

# =========================================================
# 5. ìŠ¤í¬ë˜í•‘ ë¡œì§
# =========================================================
def scrape_with_zoom_logic(driver, total_count):
    data_set = set()
    data_list = []
    rows_locator = (By.CSS_SELECTOR, "#mf_win_main_subWindow0_wframe_grd_gridBox_body_tbody > tr")
    scroll_div = driver.find_element(By.CSS_SELECTOR, "#mf_win_main_subWindow0_wframe_grd_gridBox_scrollY_div")
    
    driver.execute_script("document.body.style.zoom='25%'")
    time.sleep(0.5)
    driver.execute_script("window.dispatchEvent(new Event('resize'));")
    time.sleep(2)

    for i in range(20):
        rows = driver.find_elements(*rows_locator)
        for row in rows:
            try:
                col_data_elements = row.find_elements(By.CSS_SELECTOR, "td > nobr")
                data = tuple(col.text.strip() for col in col_data_elements)
                if data and len(data) > 5 and data not in data_set:
                    data_set.add(data)
                    data_list.append(list(data))
            except: continue
        
        if len(data_set) >= total_count: break
        try:
            scroll_div.send_keys(Keys.PAGE_DOWN)
            time.sleep(0.5)
        except: break

    driver.execute_script("document.body.style.zoom='100%'")
    return data_list

# =========================================================
# 6. ì›”ë³„ ì¡°íšŒ í•¨ìˆ˜
# =========================================================
def crawl_monthly_data(driver, year, month):
    start_dt = f"{year}-{month:02d}-01"
    if month == 12: end_dt = f"{year}-12-31"
    else: end_dt = (datetime(year, month + 1, 1) - relativedelta(days=1)).strftime("%Y-%m-%d")

    for attempt in range(1, 4):
        print(f"\nâ–¶ [ì¡°íšŒ ì‹œë„ {attempt}/3] {start_dt} ~ {end_dt}")
        try:
            wait_for_loading_bar(driver)
            
            inputs = driver.find_elements(By.XPATH, "//*[contains(text(),'ì²˜ë¦¬ì¼ì')]/following::input")
            if len(inputs) >= 2:
                inputs[0].clear()
                inputs[0].send_keys(start_dt)
                inputs[1].clear()
                inputs[1].send_keys(end_dt)

            prod_inp = driver.find_element(By.XPATH, "//*[contains(text(),'í’ˆëª…')]/following::input[1]")
            prod_inp.click()
            prod_inp.clear()
            prod_inp.send_keys("ì†Œê³ ê¸°")
            driver.find_element(By.TAG_NAME, "body").click()
            time.sleep(1)

            search_btn = driver.find_element(By.ID, "mf_win_main_subWindow0_wframe_btn_search")
            js_click(driver, search_btn)
            
            print(f"   â³ ë¡œë”© ì¤‘ (ìµœëŒ€ 40ì´ˆ)... ", end="")
            total_count = 0
            max_wait = 40
            
            for s in range(max_wait):
                try:
                    if driver.find_elements(By.ID, "___processbar2"):
                        if driver.find_element(By.ID, "___processbar2").is_displayed():
                            time.sleep(1)
                            sys.stdout.write(f"{max_wait-s}..")
                            sys.stdout.flush()
                            continue
                    
                    count_el = driver.find_element(By.ID, "mf_win_main_subWindow0_wframe_tbx_listCount")
                    count_text = count_el.text
                    numbers = re.findall(r"\d+", count_text)
                    current_count = int(numbers[0]) if numbers else 0
                    
                    if current_count > 0:
                        total_count = current_count
                        print(f" ì™„ë£Œ! (ë°œê²¬: {total_count}ê±´)")
                        break
                    
                    time.sleep(1)
                    sys.stdout.write(f"{max_wait-s}..")
                    sys.stdout.flush()
                except: time.sleep(1)

            if total_count > 0:
                print(f"   âœ… ìˆ˜ì§‘ ì‹œì‘...")
                return pd.DataFrame(scrape_with_zoom_logic(driver, total_count))
            else:
                print(f"\n   âš ï¸ ë°ì´í„° 0ê±´ (í˜¹ì€ ë¡œë”© ì‹¤íŒ¨)")
                if attempt < 3:
                    print("   ğŸ”„ ìƒˆë¡œê³ ì¹¨ í›„ ì¬ì‹œë„...")
                    driver.refresh()
                    time.sleep(5)
                    move_to_target_menu_robust(driver)
                    set_search_options(driver)
                continue

        except Exception as e:
            print(f"\n   âŒ ì˜¤ë¥˜: {str(e)[:50]}...")
            if attempt < 3:
                driver.refresh()
                time.sleep(5)
                move_to_target_menu_robust(driver)
                set_search_options(driver)
    return None

# =========================================================
# 7. KMTA ì–‘ì‹ í†µí•© (ì˜¤ë¥˜ ìˆ˜ì • í•µì‹¬ ë¡œì§)
# =========================================================
def integrate_to_master(new_safety_df):
    if new_safety_df.empty: return

    # [ìˆ˜ì •] SettingWithCopyWarning í•´ê²°
    new_safety_df = new_safety_df.copy()

    # ë°ì´í„° ì „ì²˜ë¦¬
    new_safety_df = new_safety_df.drop_duplicates(subset=['std_ym', 'êµ­ê°€', 'ë¶€ìœ„'], keep='first')
    new_safety_df['ë‹¹ì›”_ì†Œê³„'] = new_safety_df['ë‹¹ì›”_ì†Œê³„'].astype(str).str.replace(',', '')
    new_safety_df['ë‹¹ì›”_ì†Œê³„'] = pd.to_numeric(new_safety_df['ë‹¹ì›”_ì†Œê³„'], errors='coerce').fillna(0)
    new_safety_df['ë‹¹ì›”_ì†Œê³„'] = (new_safety_df['ë‹¹ì›”_ì†Œê³„'] / 1000).round(1)

    # Pivot
    pivoted = new_safety_df.pivot_table(
        index=['std_ym', 'êµ­ê°€'], 
        columns='ë¶€ìœ„', 
        values='ë‹¹ì›”_ì†Œê³„', 
        aggfunc='sum'
    ).reset_index()

    pivoted.rename(columns={'std_ym': 'std_date', 'êµ­ê°€': 'êµ¬ë¶„'}, inplace=True)
    
    new_cols_map = {}
    for col in pivoted.columns:
        if col not in ['std_date', 'êµ¬ë¶„']:
            new_cols_map[col] = f"ë¶€ìœ„ë³„_{col.replace(' ', '')}_í•©ê³„"
    pivoted.rename(columns=new_cols_map, inplace=True)

    # ==============================================================================
    # â˜… [ìˆ˜ì •] ë¶€ìœ„ë³„ í•©ê³„(Total) ê³„ì‚° ë¡œì§ ê°•í™”
    # ==============================================================================
    # 1. 'ë¶€ìœ„ë³„_'ë¡œ ì‹œì‘í•˜ëŠ” ì»¬ëŸ¼ ì¤‘ 'ê³„'ëŠ” ì œì™¸í•œ ì‹¤ì œ ë¶€ìœ„ ì»¬ëŸ¼ë§Œ ë¦¬ìŠ¤íŠ¸ì—…
    part_cols = [c for c in pivoted.columns if c.startswith('ë¶€ìœ„ë³„_') and 'ê³„_í•©ê³„' not in c]
    
    # 2. Cì—´~Mì—´(ë¶€ìœ„ë“¤)ì„ ë‹¤ ë”í•´ì„œ Nì—´(ë¶€ìœ„ë³„_ê³„_í•©ê³„)ì— ì§‘ì–´ë„£ìŒ
    # (ê¸°ì¡´ 'ë¶€ìœ„ë³„_í•©ê³„' ë³€ìˆ˜ëª… ëŒ€ì‹  ë§ˆìŠ¤í„° íŒŒì¼ê³¼ ë™ì¼í•œ 'ë¶€ìœ„ë³„_ê³„_í•©ê³„' ì‚¬ìš©)
    pivoted['ë¶€ìœ„ë³„_ê³„_í•©ê³„'] = pivoted[part_cols].sum(axis=1)
    # ==============================================================================

    # ë§ˆìŠ¤í„° íŒŒì¼ ë¡œë“œ ë° ì •ì œ
    if os.path.exists(MASTER_FILE):
        master_df = pd.read_csv(MASTER_FILE)
        
        if 'êµ¬ë¶„' not in master_df.columns:
            possible_cols = [c for c in master_df.columns if 'êµ¬ë¶„' in c]
            if possible_cols:
                print(f"   ğŸ› ï¸ ì˜ëª»ëœ ì»¬ëŸ¼ëª… ê°ì§€ ë° ìˆ˜ì •: {possible_cols[0]} -> êµ¬ë¶„")
                master_df.rename(columns={possible_cols[0]: 'êµ¬ë¶„'}, inplace=True)

        # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
        master_columns = master_df.columns.tolist()
        pivoted_aligned = pivoted.reindex(columns=master_columns, fill_value=0)
        
        target_dates = pivoted_aligned['std_date'].unique()
        master_df = master_df[~master_df['std_date'].isin(target_dates)]
        
        final_df = pd.concat([master_df, pivoted_aligned], axis=0, ignore_index=True)
    else:
        final_df = pivoted

    # ì •ë ¬
    try:
        final_df = final_df.sort_values(by=['std_date', 'êµ¬ë¶„'], ascending=[False, True])
    except KeyError:
        print("   âš ï¸ ì •ë ¬ ê¸°ì¤€ ì»¬ëŸ¼('êµ¬ë¶„')ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë‚ ì§œë¡œë§Œ ì •ë ¬í•©ë‹ˆë‹¤.")
        final_df = final_df.sort_values(by=['std_date'], ascending=False)

    final_df.to_csv(MASTER_FILE, index=False, encoding='utf-8-sig')
    print(f"   ğŸ’¾ í†µí•© ì €ì¥ ì™„ë£Œ (í•©ê³„ ì»¬ëŸ¼ ì¬ê³„ì‚°ë¨)")

# =========================================================
# 8. ë©”ì¸ ì‹¤í–‰
# =========================================================
def main():
    print("="*60)
    print("ğŸš€ [ìˆ˜ì§‘ê¸°] ì‹ì•½ì²˜ ë°ì´í„° (ì˜¤ë¥˜ ìˆ˜ì • ë° ì•ˆì •í™” ë²„ì „)")
    
    start_date_str = get_next_month_from_master()
    
    today = datetime.now()
    # [ì„¤ì •] ìˆ˜ì§‘ ì¢…ë£Œì¼: ì§€ë‚œë‹¬ ë§ì¼ (ì›” ë‹¨ìœ„ í™•ì •ì¹˜ ìˆ˜ì§‘ìš©)
    # ë§Œì•½ ì´ë²ˆ ë‹¬ ë°ì´í„°ë„ ë³´ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ë¡œì§ì„ ìˆ˜ì •í•´ì•¼ í•¨
    last_day_prev_month = today.replace(day=1) - timedelta(days=1)
    end_date_str = last_day_prev_month.strftime("%Y-%m-%d")
    
    print(f" ğŸ“… ëª©í‘œ ìˆ˜ì§‘ êµ¬ê°„: {start_date_str} ~ {end_date_str}")
    
    if start_date_str > end_date_str:
        print(" âœ… [ì™„ë£Œ] ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    driver = None
    try:
        driver = setup_driver()
        driver.get("https://impfood.mfds.go.kr/ifs/websquare/websquare.html?w2xPath=/ifs/ui/index.xml")
        time.sleep(5)
        
        close_any_popup(driver)
        move_to_target_menu_robust(driver)
        set_search_options(driver) 

        date_range = pd.date_range(start=start_date_str, end=end_date_str, freq='MS')
        
        for target_date in date_range:
            result = crawl_monthly_data(driver, target_date.year, target_date.month)
            
            if isinstance(result, pd.DataFrame) and not result.empty:
                col_names = [
                    'í’ˆëª…', 'êµ¬ë¶„', 'ë¶€ìœ„', 'êµ­ê°€', 
                    'ì „ë…„ë„_ëˆ„ê³„', 'ì „ë…„ë„_12ì›”_ëˆ„ê³„', 
                    'ë‹¹ì›”_ìƒìˆœ', 'ë‹¹ì›”_ì¤‘ìˆœ', 'ë‹¹ì›”_í•˜ìˆœ', 'ë‹¹ì›”_ì†Œê³„', 'ë‹¹í•´ë…„ë„_ëˆ„ê³„'
                ]
                
                cols = result.columns.tolist()
                result.columns = col_names[:len(cols)]

                result.insert(0, 'std_ym', target_date.strftime("%Y-%m"))
                
                mask = result['êµ­ê°€'].astype(str).str.contains('ë¯¸êµ­|í˜¸ì£¼')
                df_filtered = result[mask].copy()
                
                if not df_filtered.empty:
                    integrate_to_master(df_filtered)
                else:
                    print(f"   âš ï¸ ë¯¸êµ­/í˜¸ì£¼ ë°ì´í„° ì—†ìŒ.")
            time.sleep(2)

        print("\nğŸ‰ ëª¨ë“  ì—…ë°ì´íŠ¸ ì™„ë£Œ.")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        if driver: driver.quit()

if __name__ == "__main__":
    main()